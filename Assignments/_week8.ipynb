{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Assignment\n",
    "The dataset 'bank_marketing.csv' is related with direct marketing campaigns (phone calls) of a banking institution. The classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).\n",
    "\n",
    "Important: When you read the csv file, you might need to manipulate the columsn somehow for better printing.\n",
    "\n",
    "For more information abour the dataset, please check out the link below:\n",
    "https://archive.ics.uci.edu/dataset/222/bank+marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: import necessary libraries and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing\n",
    "Convert categorical variables into numerical; one way to do is Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(41188, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics:\n",
      "               age      duration      campaign         pdays      previous  \\\n",
      "count  41188.00000  41188.000000  41188.000000  41188.000000  41188.000000   \n",
      "mean      40.02406    258.285010      2.567593    962.475454      0.172963   \n",
      "std       10.42125    259.279249      2.770014    186.910907      0.494901   \n",
      "min       17.00000      0.000000      1.000000      0.000000      0.000000   \n",
      "25%       32.00000    102.000000      1.000000    999.000000      0.000000   \n",
      "50%       38.00000    180.000000      2.000000    999.000000      0.000000   \n",
      "75%       47.00000    319.000000      3.000000    999.000000      0.000000   \n",
      "max       98.00000   4918.000000     56.000000    999.000000      7.000000   \n",
      "\n",
      "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
      "count  41188.000000    41188.000000   41188.000000  41188.000000  41188.000000  \n",
      "mean       0.081886       93.575664     -40.502600      3.621291   5167.035911  \n",
      "std        1.570960        0.578840       4.628198      1.734447     72.251528  \n",
      "min       -3.400000       92.201000     -50.800000      0.634000   4963.600000  \n",
      "25%       -1.800000       93.075000     -42.700000      1.344000   5099.100000  \n",
      "50%        1.100000       93.749000     -41.800000      4.857000   5191.000000  \n",
      "75%        1.400000       93.994000     -36.400000      4.961000   5228.100000  \n",
      "max        1.400000       94.767000     -26.900000      5.045000   5228.100000  \n"
     ]
    }
   ],
   "source": [
    "# read the CSV with the ; separator\n",
    "df = pd.read_csv('data/bank_marketing.csv', sep=';')\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above code that there are no missing values in the dataset.\n",
    "\n",
    "Let's get an inventory of all the unqiue values in each feature so we can plan out the preprocessing approach. This also can be a method to spot bad data or slight variations within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'age':\n",
      "[56 57 37 40 45 59 41 24 25 29 35 54 46 50 39 30 55 49 34 52 58 32 38 44\n",
      " 42 60 53 47 51 48 33 31 43 36 28 27 26 22 23 20 21 61 19 18 70 66 76 67\n",
      " 73 88 95 77 68 75 63 80 62 65 72 82 64 71 69 78 85 79 83 81 74 87 91 86\n",
      " 98 94 84 92 89]\n",
      "\n",
      "Unique values in 'job':\n",
      "['housemaid' 'services' 'admin.' 'blue-collar' 'technician' 'retired'\n",
      " 'management' 'unemployed' 'self-employed' 'unknown' 'entrepreneur'\n",
      " 'student']\n",
      "\n",
      "Unique values in 'marital':\n",
      "['married' 'single' 'divorced' 'unknown']\n",
      "\n",
      "Unique values in 'education':\n",
      "['basic.4y' 'high.school' 'basic.6y' 'basic.9y' 'professional.course'\n",
      " 'unknown' 'university.degree' 'illiterate']\n",
      "\n",
      "Unique values in 'default':\n",
      "['no' 'unknown' 'yes']\n",
      "\n",
      "Unique values in 'housing':\n",
      "['no' 'yes' 'unknown']\n",
      "\n",
      "Unique values in 'loan':\n",
      "['no' 'yes' 'unknown']\n",
      "\n",
      "Unique values in 'month':\n",
      "['may' 'jun' 'jul' 'aug' 'oct' 'nov' 'dec' 'mar' 'apr' 'sep']\n",
      "\n",
      "Unique values in 'day_of_week':\n",
      "['mon' 'tue' 'wed' 'thu' 'fri']\n",
      "\n",
      "Unique values in 'duration':\n",
      "[ 261  149  226 ... 1246 1556 1868]\n",
      "\n",
      "Unique values in 'campaign':\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 19 18 23 14 22 25 16 17 15 20 56\n",
      " 39 35 42 28 26 27 32 21 24 29 31 30 41 37 40 33 34 43]\n",
      "\n",
      "Unique values in 'pdays':\n",
      "[999   6   4   3   5   1   0  10   7   8   9  11   2  12  13  14  15  16\n",
      "  21  17  18  22  25  26  19  27  20]\n",
      "\n",
      "Unique values in 'previous':\n",
      "[0 1 2 3 4 5 6 7]\n",
      "\n",
      "Unique values in 'poutcome':\n",
      "['nonexistent' 'failure' 'success']\n",
      "\n",
      "Unique values in 'emp.var.rate':\n",
      "[ 1.1  1.4 -0.1 -0.2 -1.8 -2.9 -3.4 -3.  -1.7 -1.1]\n",
      "\n",
      "Unique values in 'cons.price.idx':\n",
      "[93.994 94.465 93.918 93.444 93.798 93.2   92.756 92.843 93.075 92.893\n",
      " 92.963 92.469 92.201 92.379 92.431 92.649 92.713 93.369 93.749 93.876\n",
      " 94.055 94.215 94.027 94.199 94.601 94.767]\n",
      "\n",
      "Unique values in 'cons.conf.idx':\n",
      "[-36.4 -41.8 -42.7 -36.1 -40.4 -42.  -45.9 -50.  -47.1 -46.2 -40.8 -33.6\n",
      " -31.4 -29.8 -26.9 -30.1 -33.  -34.8 -34.6 -40.  -39.8 -40.3 -38.3 -37.5\n",
      " -49.5 -50.8]\n",
      "\n",
      "Unique values in 'euribor3m':\n",
      "[4.857 4.856 4.855 4.859 4.86  4.858 4.864 4.865 4.866 4.967 4.961 4.959\n",
      " 4.958 4.96  4.962 4.955 4.947 4.956 4.966 4.963 4.957 4.968 4.97  4.965\n",
      " 4.964 5.045 5.    4.936 4.921 4.918 4.912 4.827 4.794 4.76  4.733 4.7\n",
      " 4.663 4.592 4.474 4.406 4.343 4.286 4.245 4.223 4.191 4.153 4.12  4.076\n",
      " 4.021 3.901 3.879 3.853 3.816 3.743 3.669 3.563 3.488 3.428 3.329 3.282\n",
      " 3.053 1.811 1.799 1.778 1.757 1.726 1.703 1.687 1.663 1.65  1.64  1.629\n",
      " 1.614 1.602 1.584 1.574 1.56  1.556 1.548 1.538 1.531 1.52  1.51  1.498\n",
      " 1.483 1.479 1.466 1.453 1.445 1.435 1.423 1.415 1.41  1.405 1.406 1.4\n",
      " 1.392 1.384 1.372 1.365 1.354 1.344 1.334 1.327 1.313 1.299 1.291 1.281\n",
      " 1.266 1.25  1.244 1.259 1.264 1.27  1.262 1.26  1.268 1.286 1.252 1.235\n",
      " 1.224 1.215 1.206 1.099 1.085 1.072 1.059 1.048 1.044 1.029 1.018 1.007\n",
      " 0.996 0.979 0.969 0.944 0.937 0.933 0.927 0.921 0.914 0.908 0.903 0.899\n",
      " 0.884 0.883 0.881 0.879 0.873 0.869 0.861 0.859 0.854 0.851 0.849 0.843\n",
      " 0.838 0.834 0.829 0.825 0.821 0.819 0.813 0.809 0.803 0.797 0.788 0.781\n",
      " 0.778 0.773 0.771 0.77  0.768 0.766 0.762 0.755 0.749 0.743 0.741 0.739\n",
      " 0.75  0.753 0.754 0.752 0.744 0.74  0.742 0.737 0.735 0.733 0.73  0.731\n",
      " 0.728 0.724 0.722 0.72  0.719 0.716 0.715 0.714 0.718 0.721 0.717 0.712\n",
      " 0.71  0.709 0.708 0.706 0.707 0.7   0.655 0.654 0.653 0.652 0.651 0.65\n",
      " 0.649 0.646 0.644 0.643 0.639 0.637 0.635 0.636 0.634 0.638 0.64  0.642\n",
      " 0.645 0.659 0.663 0.668 0.672 0.677 0.682 0.683 0.684 0.685 0.688 0.69\n",
      " 0.692 0.695 0.697 0.699 0.701 0.702 0.704 0.711 0.713 0.723 0.727 0.729\n",
      " 0.732 0.748 0.761 0.767 0.782 0.79  0.793 0.802 0.81  0.822 0.827 0.835\n",
      " 0.84  0.846 0.87  0.876 0.885 0.889 0.893 0.896 0.898 0.9   0.904 0.905\n",
      " 0.895 0.894 0.891 0.89  0.888 0.886 0.882 0.88  0.878 0.877 0.942 0.953\n",
      " 0.956 0.959 0.965 0.972 0.977 0.982 0.985 0.987 0.993 1.    1.008 1.016\n",
      " 1.025 1.032 1.037 1.043 1.045 1.047 1.05  1.049 1.046 1.041 1.04  1.039\n",
      " 1.035 1.03  1.031 1.028]\n",
      "\n",
      "Unique values in 'nr.employed':\n",
      "[5191.  5228.1 5195.8 5176.3 5099.1 5076.2 5017.5 5023.5 5008.7 4991.6\n",
      " 4963.6]\n",
      "\n",
      "Unique values in 'y':\n",
      "['no' 'yes']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns to check for unique values\n",
    "columns_to_check = df.columns\n",
    "\n",
    "# Print unique values for each column\n",
    "for column in columns_to_check:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in '{column}':\\n{unique_values}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can:\n",
    "- remove duplicate entries from the dataset.\n",
    "- remove bad training data like minors or unmanaged living records (ages over 100) from the test set.\n",
    "- validate there are not any NULL values.\n",
    "- potentially replace '999' in the pdays feature with 'unknown' since it seems to be a placeholder.\n",
    "\n",
    "The dataset has many binary questions filled in with 'unknown' values. One experiment to look at later in this notebook would be how does removing those rows of data impact the model's performance? Could we create synthetic training data that improves the model performance once the vague data is removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicates: 12\n",
      "\n",
      "Number of duplicates after dropping: 0\n"
     ]
    }
   ],
   "source": [
    "# we can remove the contact feature since there will not be any correlation between contact and the target variable\n",
    "df.drop('contact', axis=1, inplace=True)\n",
    "\n",
    "# check for duplicates\n",
    "print(\"\\nNumber of duplicates:\", df.duplicated().sum())\n",
    "\n",
    "# dop dupicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"\\nNumber of duplicates after dropping:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can find any bad data like minors in the age column.This does not benefit our training data because they can skew our model's bias by showing many 'non defaulted' data rows, even though they have not really had the opportunity to default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset before dropping bad data:  (41176, 20)\n",
      "Invalid age entries:\n",
      "        age      job marital education default  housing     loan month  \\\n",
      "37140   17  student  single   unknown      no      yes       no   aug   \n",
      "37539   17  student  single  basic.9y      no      yes       no   aug   \n",
      "37558   17  student  single  basic.9y      no      yes       no   aug   \n",
      "37579   17  student  single  basic.9y      no  unknown  unknown   aug   \n",
      "38274   17  student  single   unknown      no       no      yes   oct   \n",
      "\n",
      "      day_of_week  duration  campaign  pdays  previous poutcome  emp.var.rate  \\\n",
      "37140         wed       432         3      4         2  success          -2.9   \n",
      "37539         fri       182         2    999         2  failure          -2.9   \n",
      "37558         fri        92         3      4         2  success          -2.9   \n",
      "37579         fri       498         2    999         1  failure          -2.9   \n",
      "38274         tue       896         1      2         2  success          -3.4   \n",
      "\n",
      "       cons.price.idx  cons.conf.idx  euribor3m  nr.employed    y  \n",
      "37140          92.201          -31.4      0.884       5076.2   no  \n",
      "37539          92.201          -31.4      0.869       5076.2   no  \n",
      "37558          92.201          -31.4      0.869       5076.2   no  \n",
      "37579          92.201          -31.4      0.869       5076.2  yes  \n",
      "38274          92.431          -26.9      0.742       5017.5  yes  \n",
      "No invalid month entries.\n",
      "No invalid day_of_week entries.\n",
      "No invalid y entries.\n",
      "Shape of the dataset after dropping bad data:  (41171, 20)\n"
     ]
    }
   ],
   "source": [
    "valid_months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "valid_days = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']\n",
    "valid_y = ['yes', 'no']\n",
    "\n",
    "# shape of the dataset before dropping bad data\n",
    "print(\"Shape of the dataset before dropping bad data: \", df.shape)\n",
    "\n",
    "# Search for invalid age values (under 18 or over 100)\n",
    "invalid_age = df[(df['age'] < 18) | (df['age'] > 100)]\n",
    "print(\"Invalid age entries:\\n\", invalid_age)\n",
    "\n",
    "# Drop invalid age values\n",
    "df = df.drop(invalid_age.index)\n",
    "\n",
    "# Validate 'month' column\n",
    "invalid_month = df[~df['month'].isin(valid_months)]\n",
    "if invalid_month.empty:\n",
    "    print(\"No invalid month entries.\")\n",
    "else:\n",
    "    print(\"Invalid month entries:\\n\", invalid_month)\n",
    "\n",
    "# Validate 'day_of_week' column\n",
    "invalid_day = df[~df['day_of_week'].isin(valid_days)]\n",
    "if invalid_day.empty:\n",
    "    print(\"No invalid day_of_week entries.\")\n",
    "else:\n",
    "    print(\"Invalid day_of_week entries:\\n\", invalid_day)\n",
    "\n",
    "# Validate 'y' column\n",
    "invalid_y = df[~df['y'].isin(valid_y)]\n",
    "if invalid_y.empty:\n",
    "    print(\"No invalid y entries.\")\n",
    "else:\n",
    "    print(\"Invalid y entries:\\n\", invalid_y)\n",
    "\n",
    "# shape of the dataset after dropping bad data\n",
    "print(\"Shape of the dataset after dropping bad data: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Scale the features (important for KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split into training and test sets (80 & 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Find the optimal K using 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Plot the error rate for different K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Find and print the optimal K (K with the minimum error rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Train the final KNN model with the optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
