{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm\n",
    "\n",
    "First, import the neccessary libraries and read the csv file in as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('data/LoanStats3a.csv', skiprows=1, low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take inventory of features we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take inventory of the unique values in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "unique_values = {col: df[col].unique() for col in df.columns}\n",
    "for col, values in unique_values.items():\n",
    "    print(f\"Unique values in '{col}' column: {values}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the datatypes to know how the data was read in by Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(list(df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What kind of interest rate are borrowers paying? (min, max and mean rate values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# convert percent values to floats\n",
    "df.loc[:, 'int_rate'] = df['int_rate'].str.rstrip('%').astype('float') / 100\n",
    "\n",
    "# get int rate summary statistics\n",
    "print(\"Summary statistics for the interest rate column:\")\n",
    "df.describe()\n",
    "\n",
    "# reconverting to percent\n",
    "df.loc[:, 'int_rate'] = df['int_rate'] * 100\n",
    "\n",
    "# print the answer.\n",
    "print(\"\\nThe lowest interest rate (%) is: \", df['int_rate'].min())    \n",
    "print(\"The highest interest rate (%) is: \", df['int_rate'].max())\n",
    "print(\"The average interest rate (%) is: \", df['int_rate'].mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How long are the loan terms? (Min, Max and Mean term values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# count the number of NaN values in the 'term' column\n",
    "nan_count = df['term'].isna().sum()\n",
    "print(f\"Number of NaN values in 'term' column: {nan_count}\")\n",
    "\n",
    "# print the unique values in the 'term' column\n",
    "print(\"Unique values in 'term' column: \", df['term'].unique())\n",
    "\n",
    "## drop the NaN values from the 'term' column\n",
    "# print the number of rows before dropping NaN values\n",
    "pre = df.shape[0]\n",
    "print(f\"\\nNumber of rows before dropping NaN values: {pre}\")\n",
    "\n",
    "# drop the NaN values from the 'term' column\n",
    "df = df.dropna(subset=['term'])\n",
    "\n",
    "# print the number of rows after dropping NaN values\n",
    "post = df.shape[0]\n",
    "print(f\"Number of rows after dropping NaN values: {post}\")\n",
    "\n",
    "# convert values to integers for computations\n",
    "df.loc[:, 'term'] = df['term'].astype(str)\n",
    "df.loc[:, 'term'] = df['term'].str.replace(' months', '').astype(int)\n",
    "\n",
    "# calculate the term feature's statistics summary\n",
    "print(\"\\nSummary statistics for the 'term' column:\")\n",
    "print(df['term'].describe())\n",
    "\n",
    "# print the answer\n",
    "print(f\"\\nThe shortest term is: {df['term'].min()} months\")\n",
    "print(f\"The longest term is: {df['term'].max()} months\")\n",
    "print(f\"The average term is: {df['term'].mean().round()} months\") # rounded to nearest whole number to account for significant figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How much are people borrowing? (Min, Max and Mean amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "nan_count = df.loc[:, 'loan_amnt'].isna().sum()\n",
    "print(f\"Number of NaN values in the 'loan_amnt' column: {nan_count}\\n\")\n",
    "\n",
    "print(df.loc[:, 'loan_amnt'].describe())\n",
    "\n",
    "# print the answer\n",
    "print(\"\\nThe smallest loan amount is: $\", df['loan_amnt'].min())\n",
    "print(\"The largest loan amount is: $\", df['loan_amnt'].max())\n",
    "print(\"The average loan amount is: $\", df['loan_amnt'].mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What are people taking these loans out for? (list the items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(\"Unique values in 'purpose' column:\", list(df['purpose'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Are the borrowers renters or homeowners? (list the ownership status items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(\"The borrowers are categorized into the following living situations:\", list(df['home_ownership'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Where do these borrowers live? (list of states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(\"The borrowers live in the following states:\", list(df['addr_state'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use a predictor and evaluate your model. (You can use a machine learning classifier, and evaluate your model with metrics, e.g., you can predict the failed vs successful loans)\n",
    "\n",
    "Let's start by categorizing the feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Print non-numeric columns\n",
    "for column in df.columns:\n",
    "    try:\n",
    "        pd.to_numeric(df[column])\n",
    "    except:\n",
    "        print(f\"Column '{column}' is non-numeric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter out non-numeric columns to focus on the numeric columns with plenty of valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# specify the columns to be used\n",
    "selected_features = ['loan_amnt', 'annual_inc', 'dti', 'int_rate']\n",
    "\n",
    "# remove redundant context within the loan_status column. We just care if they defaulted or not.\n",
    "df['loan_status'] = df['loan_status'].str.replace(\"Does not meet the credit policy. Status:\", \"\", regex=False)\n",
    "\n",
    "# defined function to convert loan_status to binary\n",
    "def map_loan_status(status):\n",
    "    if pd.isna(status):\n",
    "        return np.nan\n",
    "    return 1 if isinstance(status, str) and 'Fully Paid' in status else 0 # 1 for fully paid, 0 for charged off\n",
    "\n",
    "# apply the encoding to the loan_status column\n",
    "df['loan_status'] = df['loan_status'].apply(map_loan_status)\n",
    "\n",
    "# drop rows with any NaN values in the selected features and loan_status\n",
    "df_clean = df[selected_features + ['loan_status']].dropna()\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was difficult to wrangle the 'loan_status' column to be binary, however, isolating the string text worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# store dataFrame values in X and y\n",
    "X_clean = df_clean[selected_features].copy()\n",
    "y_clean = df_clean['loan_status']\n",
    "\n",
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=0.2, random_state=42\n",
    ")\n",
    "# print unique values in the training and test sets to confirm the presence of predict labels.\n",
    "print(\"Unique values in X_train:\")\n",
    "print(X_train.nunique())\n",
    "print(\"\\nUnique values in X_test:\")\n",
    "print(X_test.nunique())\n",
    "print(\"\\nUnique values in y_train:\")\n",
    "print(y_train.nunique())\n",
    "print(\"\\nUnique values in y_test:\")\n",
    "print(y_test.nunique())\n",
    "\n",
    "# scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# train a KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nKNN Model Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through clear data use and understanding, the model was fit and able to be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# call confusion matrix function\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The model is heavily leaning towards predicting loans as fully paid inaccurately. This can be a huge impact to businesses because if you're categorizing loans as not risky by predicting them to be fully paid, that can expose your business to extensive losses through loan defaults. I believe based on the number of true negatives that there was an imbalance in the data set which led the model to automatically lean towards an outcome of fully paid if it was somewhere in the middle. Moving forward and building off this, analysts could look at oversampling or undersampling along with trying different models in addition to the KNN model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
